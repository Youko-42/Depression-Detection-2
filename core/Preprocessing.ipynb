{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMuEtKFOdMURjMDlqWLWXZB"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VedqAasnEz4S"},"source":["数据预处理"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Osg_Ma9U-cak","executionInfo":{"status":"ok","timestamp":1605885237783,"user_tz":-480,"elapsed":464,"user":{"displayName":"Yangzi Zhong","photoUrl":"","userId":"14597158729399505185"}},"outputId":"4bf5bde2-f1a6-473b-9e2a-bf2d5e946a1e"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"," \n","path = \"/content/gdrive/My Drive/Independent\"\n","os.chdir(path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iEZexjYM-tC4"},"source":["# 获取文本\n","import json\n","\n","users_label = [] # 用户标签\n","users_posts = [] # 用户发言\n","index = 0    # 用户序号\n","\n","# 读取文本\n","def read_text(file_path):\n","    global index\n","\n","    text = open(file_path, 'r', encoding='UTF-8')\n","    line = text.readline()\n","    while line:\n","        if (len(line.strip()) != 0):\n","            setting = json.loads(line[1:-2])\n","            posts = setting['posts']\n","            label = setting['label']\n","\n","            add_lable(label)\n","            add_posts(posts)\n","\n","            index = index + 1\n","            line = text.readline()\n","\n","        if (index == 1000):\n","            break\n","\n","    return users_label, users_posts\n","\n","# 记录用户标签\n","def add_lable(label):\n","    if (label == \"depression\"):\n","        users_label.append(1)\n","    else:\n","        users_label.append(0)\n","\n","# 记录用户发言\n","def add_posts(posts):\n","    user_posts = \"\"\n","    for post in posts:\n","        user_posts = user_posts + \" \" + post[1]\n","    users_posts.append(user_posts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OH03T-NY-vTO"},"source":["# 预处理\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# 词频\n","def count_vec(users_posts):\n","    count = CountVectorizer(stop_words='english')\n","    # 计算各个词语出现的次数\n","    users_posts = count.fit_transform(users_posts)\n","    return users_posts\n","\n","# TF-IDF\n","def tf_idf(users_posts):\n","    tfidf = TfidfVectorizer(stop_words='english')\n","    users_posts = tfidf.fit_transform(users_posts)\n","    return users_posts\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AHi_L00C-vvn"},"source":["# 保存\n","from scipy import sparse\n","\n","def save(users_posts, users_label):\n","    sparse.save_npz(\"./result/v_count_posts.npz\", users_posts, False)\n","\n","    file = open(\"./result/v_label.txt\", \"w\")\n","    for user_label in users_label:\n","        file.write(str(user_label) + \"\\n\")\n","    file.close()\n","\n","def read_list(path):\n","    result = []\n","    with open(path, \"r\") as f:\n","        for line in f:\n","            result.append(line.strip(\"\\n\"))\n","\n","    return result\n","\n","def read_npz(path):\n","    sparse_matrix = sparse.load_npz(path)\n","    return sparse_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i5x05aYD-zP3"},"source":["import numpy as np\n","\n","# 获取用户标签和发言\n","file_path = \"./docs/validation\"\n","users_label, users_posts = read_text(file_path)\n","\n","# 文本向量化\n","users_posts = count_vec(users_posts)\n","#users_posts = tf_idf(users_posts)\n","\n","# 保存至本地\n","save(users_posts, users_label)"],"execution_count":null,"outputs":[]}]}